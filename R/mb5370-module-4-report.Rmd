---
title: "mb5370-module-4-report"
author: "Emilee Chamberland"
date: "2023-05-04"
output: html_document
---



# **Workshop 3: Reproducible Work**

## 4.1 Setting up Git and Github

Github allows version control of your work and shareability of your code, notes, and figures.

```{r}
#install.packages("usethis") #after setting up Github account this package is used to connect R Studio to your github repository
library(usethis)
use_git_config(user.name = "e-m-cham198", user.email = "emilee.chamberland@my.jcu.edu.au")
```

## 4.11 Assignement: End-to-end analysis in R

Obtaining data from QFISH, will be used for assignment
Download as csv and import data
```{r}
turtlecatch <- read.csv("~/JCU _2023/SP1/MB5370/Module4_R/github/mb5370/data/turtlecatch.csv")
```

```{r}
turtlecatch
```
# **Workshop 4: Data Wrangling in R**

## 5.3 What is a tibble?

Tibbles are basically a data frame. It's a slightly adjusted data frame designed to keep up with recent advances in R. 

```{r}
#Load tidyverse package - tibble is a part of the core tidyverse package
library(tidyverse)
```

#### Convert regular data frames into tibbles, use **as_tibble()**
```{r}
iris #built in iris data
str(iris) # check out the data

as_tibble(iris) # convert data frame into tibble
```

There are differences with how tibbles are presented in the console. Can also build a tibble from scratch by passing data directly to it as opposed to importing data from a csv.
Tibbles allow you to refer to variables that you just created
**For example:**
```{r}
tibble(
  x = 1:5,
  y = 1,
  z = x^2 + y #call new variables to produce new column values
)
```
Using tibble to build data frame was much easier than using the data.frame() function. It would take more steps as you couldn't use a function like we did above for z.
Can also use non-syntactic variables in your tibbles (ie using spaces or special characters, etc), we just need to refer to them with backticks so R can usnderstand them. Although it's still not recommended to use spaces it's better to stick with underscores or full stops.
**Example**
```{r}
tb <- tibble(
  `:)` = "smile", 
  ` ` = "space",
  `2000` = "number"
)

tb #view the tibble we created
```

#### Tribbles

Stands for **transposed tibble**. This function is to help you do data entry directly in your script making is possible to layout small amounts of data in an easy to read form.

```{r}
tribble(
  ~x, ~y, ~z, #using "~" denotes the column headings
  #--|---|---
  "a", 2, 3.6, #data row one
  "b", 1, 8.5  #data row two
)
```

### Differences between tibbles and data.frame
1. Printing: Tibbles only print the first 10 lines making it easier to work with large data
2. Tibbles print the type of each column variable next to its name (i.e. character, string, numeric)
3. Tibbles help your console from getting overwhelmed by printing massive amounts of data

#### Let's take a look

```{r}
tibble(
  a = lubridate::now() + runif(1e3) * 86400,
  b = lubridate::today() + runif(1e3) * 30,
  c = 1:1e3,
  d = runif(1e3),
  e = sample(letters, 1e3, replace = TRUE)
)
```
**NYC Flights**
```{r}
#install.packages("nycflights13") #install package
library(nycflights13) #load package

nycflights13::flights %>%
  print(n = 10, width = Inf) #n = designates number of rows and width = Inf displays every column
```
There's a range of other things that can be done to interrogate the data. Here's a few options
- **:** if more than n rows, print only m rows,
- Use **options(tibble.print_min = INF)** to always show all rows.
- Use **options(tibble.width = Inf)** to always print all columns, regardless of width of screen
- Use R's built-in viewer with **View()**

#### Set global options for R session:
```{r}
options(tibble.width = Inf)
```

### More useful things

```{r}
df <- tibble( #build a tibble
  x = runif(5),
  y = rnorm(5)
)

#Extract by name
df$x

df[["x"]] #different method to do the same thing

#Extract by row position
df[[1]]

#Extract by exact position
df[[2,2]]

df %>% .$x #(%>%) pipes - a new way to do things to variables in R

df %>% .[["x"]]
```

Another benefit of tibbles is that they won't do partial matching. If the variable you call out isn't an exact match to what's in the dataframe a warning will be generated

```{r}
df <- tibble(
  xxx = runif(5),
  y = rnorm(5)
)

df$xx #call isn't an exact match to the variable above
```

There are some downsides to tibbles, one of which is they don't always work with older functions in R. If you encounter this problem turn the tibble back into a standard R dataframe using **as.data.frame()**

```{r}
df <- data.frame(abc = 1, xyz = "a") #build the dataframe
df #call the dataframe
df$x #call by name
df[, "xyz"] # call the exact position
```

## 5.4 Importing Data

How to import data into R and how to read plain-text rectangular files into R including .csv files

#### Using the **readr** pacakage
**readr** is a part of the tidyverse package. Most of the functions are concerned with turning flat files into dataframes
 - **read_csv()**: reads comma delimited files, **read_csv2()**: reads semicolon separated files, **read_tsv()**: reads tab delimited files, and **read_delim()**: reads in files with any delimiter
 - **read_fwf()**: reads fixed width files, can specify by their widths with **fwf_widths()** or their position with **fwf_positions()**. **read_table()** reads a common variation of fixed width files where columns are separated by white space
 
#### Example of how to call a file using file path

heights <- read_csv("data/heights.csv")
#> Rows: 1192 Columns: 6
#> ── Column specification ────────────────────────────────────────────────────────
#> Delimiter: ","
#> chr (2): sex, race
#> dbl (4): earn, height, ed, age
#> 
#> ℹ Use `spec()` to retrieve the full column specification for this data.
#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

#### Running read_csv code

```{r}
read_csv("a,b,c
         1,2,3
         4,5,6")
```
Rows: 2 Columns: 3── Column specification ─────────────────────────────────────────────────────────────
Delimiter: ","
dbl (3): a, b, c
ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.



Using this you can also skip a line, for example if you have metadata at the top you can skip over

#### TO skip over a line you can use **skip = n**
```{r}
read_csv("The first line of metadata
  The second line of metadata
  x,y,z
  1,2,3", skip = 2) #skips 2nd line
```
> read_csv("The first line of metadata
+   The second line of metadata
+   x,y,z
+   1,2,3", skip = 2)
Rows: 1 Columns: 3── Column specification ────────────────────────────────────────────
Delimiter: ","
dbl (3): x, y, z
ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

#### Or you can use **comment = "#"**
```{r}
read_csv("# A comment I want to skip
  x,y,z
  1,2,3", comment = "#") #another way to skip a line 
```
> read_csv("# A comment I want to skip
+   x,y,z
+   1,2,3", comment = "#")
Rows: 1 Columns: 3── Column specification ────────────────────────────────────────────
Delimiter: ","
dbl (3): x, y, z
ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

If your data doesn't include column names use **col_names = FALSE** to tell **read_csv()** to not treat the first row as column names
```{r}
read_csv("1,2,3\n4,5,6", col_names = FALSE) #tells R that your data doesn't have column names
```
read_csv("1,2,3\n4,5,6", col_names = FALSE) #tells R that your data doesn't have column names
Rows: 2 Columns: 3── Column specification ────────────────────────────────────────────
Delimiter: ","
dbl (3): X1, X2, X3
ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

```{r}
#col_names = tells read_csv what characters you want as the column names
read_csv("1,2,3\n4,5,6", col_names = c("x", "y", "z")) #"\n" is a shortcut for adding a new line
```

#### Setting no data values

Important as assuming a no data value as a zero can have major impacts on your analysis

```{r}
read_csv("a,b,c\n1,2,.", na = ".") #tells R that there is no data where a "." is present
```

## 5.5 Tidying data using Tidyr

In this section we'll be learning how to tidy our data using the **tidyr** package (part of the core tidyverse)

```{r}
#library(tidyverse) #make sure to load library if needed
```

### 5.5.1 Tidy data

```{r}
table1 #Note that table 1 is "tidy", you should strive to always have your data in this format
```
```{r}
table2 #these four examples are not "tidy"
table3
table4a
table4b
```

#### **3 Rules to make a tidy table**
1. Each variable must have its own column
2. Each observation must have its own row
3. Each value must have its own cell

above rules are interrelated, so you can't satisfy only 2 of the three
**Instructions to meet the rules**
1. Put each dataset in a tibble
2. Put each variable in a column

This makes sure that you have a consistent data structure making it easier to work with and having variables in columns allows R to work with the vectors **This makes for one less headache!!**

#### Start with a tidy dataset (table1)

```{r}
#Compute rate per 10,000
table1 %>% 
  mutate(rate = cases / population * 10000)

# Compute cases per year
table1 %>% 
  count(year, wt = cases)

# Visualise changes over time
library(ggplot2)
ggplot(table1, aes(year, cases)) + 
  geom_line(aes(group = country), colour = "grey50") + 
  geom_point(aes(colour = country))
```

### 5.5.2 Spreading and gatherig data tables

While working with tidy data is super handy, most likely the data will be untidy. So let's go through the steps of tidying data

*First step* understanding what each variable and observation actually means

**Understanding data structures can translate into better data entry and how you enter the data into excel**

*Second step* to resolve one of the two common problems with untidy data
1. One variable is spread across multiple columns
2 One observation is scattered across multiple rows

#### How to fix
To fix we'll explore the use of **pivot_longer()** (makes datasets “longer” by increasing the number of rows and decreasing the number of columns.) and **pivot_wider()** (handles an observation scattered across multiple rows)

**pivot_longer()** and table4a
```{r}
table4a #column names 1999 & 2000 represent values of the year variable, the values in the 1999 and 2000 columns represent values of the cases variable, and each row represents 2 observations, not one.
```

To tidy this we need to pivot the offending columns into a new pair of variables. To describe this we need 3 parameters
1. the set of columns whose names are values, not variables. In this example, those are the columns 1999 and 2000.
2. the name of the variable to move the column names to. Here it is **year**
3. THe name of the variable to move the column values to. Here is it **cases**

```{r}
table4a %>%
  pivot_longer(c("1999", "2000"), names_to = "year", values_to = "cases") 
```
Here you can see instead of having one column for 1999 and one for 2000 they have bee changed to values in the new column "year" and the values that were once under the 1999 and 2000 columns are in the new "cases" column.

**Try with table4b**
```{r}
table4b %>%
  pivot_longer(c("1999", "2000"), names_to = "year", values_to = "population") #similar to table 4a but istead of cases this table uses population
```
#### Combine the tidied version
To do this we'll need to use **dplyr::left_join()**
```{r}
tidy4a <- table4a %>% 
  pivot_longer(c(`1999`, `2000`), names_to = "year", values_to = "cases") #tidy 4a
tidy4b <- table4b %>% 
  pivot_longer(c(`1999`, `2000`), names_to = "year", values_to = "population") #tidy 4b
left_join(tidy4a, tidy4b) #join the two tidied tables together
```

#### **Using pivot_wider()**
This handles an observation scattered across multiple rows

```{r}
table2 # in this table an obervation is a country in a year with the observation spread across two rows
```
How do we make this tidy?
1. The column to take variables from is *type*
2. The column to take values from is *count*

```{r}
table2 %>%
    pivot_wider(names_from = type, values_from = count)
```

### 5.5.3 Separating and uniting data tables

For table3, one column contains 2 variables (cases and population). To address this use the **separate()** function to separate one column into multiple columns

```{r}
table3 #untidy table

table3 %>%
  separate(rate, into = c("cases", "population")) #cases and populations now separated

table3 %>%
  separate(rate, into = c("cases", "population"), sep = "/") # use sep = to specify where you want the values separated

table3 %>% 
  separate(rate, into = c("cases", "population"), convert = TRUE) #since values in case and pop columns are actually numbers, we want to ask separate() to convert them to better types using convert = TRUE

table3 %>% 
  separate(year, into = c("century", "year"), sep = 2) # can also use to separate the last two digits of each year, less tidy but can still be useful
```
#### Inverse of separate : **unite()**

table5 we want to rejoin two columns, in this case the century and year columns

```{r}
table5 %>% 
  unite(new, century, year, sep = "") # combines the first 2 and last 2 digits of the years
```

### 5.5.4 Handling missing values

Missing values in datasets are very common. Can be seen as an NA or just a blank cell. The way data is missing is important and matters when tidying your data.
An *NA* **(explicit absence)** indicates the presence of absent data, a *blank cell* **(implicit absence)** just indicates the absence of data.

```{r}
stocks <- tibble( #implicit values made explicit by putting years in columns
  year   = c(2015, 2015, 2015, 2015, 2016, 2016, 2016),
  qtr    = c(   1,    2,    3,    4,    2,    3,    4),
  return = c(1.88, 0.59, 0.35,   NA, 0.92, 0.17, 2.66)
)

stocks %>% 
  pivot_wider(names_from = year, values_from = return) 

stocks %>% #missing values may not be important in other representations of the data, can set values_drop_na = TRUE in pivot_longer to turn explicit to implicit
  pivot_wider(names_from = year, values_from = return) %>% 
  pivot_longer(
    cols = c(`2015`, `2016`), 
    names_to = "year", 
    values_to = "return", 
    values_drop_na = TRUE
  )
```

Another important tool for making missing values explicit (clear to you that they represent actual missing data values) is **complete()**. 

```{r}
stocks
stocks %>% 
  complete(year, qtr) #takes a set of columns and finds all the unique combinations and then ensures the original dataset contains all of those values, includign filling in explicit NA
```


**fill()** can be used to fill in missing values that were meant to be carried forward in the data entry process

```{r}
treatment <- tribble(
  ~ person,           ~ treatment, ~response,
  "Derrick Whitmore", 1,           7,
  NA,                 2,           10,
  NA,                 3,           9,
  "Katherine Burke",  1,           4
)
treatment

treatment %>% 
  fill(person) #carries last observation forward (replaces with most recent non-missing value)
#> # A tibble: 
```
## 5.6 Learning relational data

To work with relational data we will be using **dplyr**. It's a package focused on the grammar of data manipulation, specialized for doing data analysis.
dplyr provides the following verbs to make common data analysis operations easier:
1. *Mutating* joins - add new variables to one dataframe from matching observations in another
2. *filtering* joins - filter observations from one dataframe based on whether or not they match an observation in the other table
3. *Set* operations - treat observations as if they are set elements

Let's explore
```{r}
#load packages and datasets
#library(tidyverse)
#library(nycflights13)

airlines #lets you look up full carrier name from abbrev
airports # gives info about each airport, identified by code
planes #givees info about each plane, id'd by tailnumber
weather # gives weather at each NYC airport by hour

```
Here's how they're all connected :
- flights connects to planes via a single variable, tailnum.
- flights connects to airlines through the carrier variable.
- flights connects to airports in two ways: via origin and dest variables.
- flights connects to weather via origin (the location), and year, month, day and hour (the time).

### 5.6.1 Joining datasets

To join datasets need to identify the *keys* -> a variable (or set of variables) that uniquely identifies an observation.
2 Types:
**Primary**: uniquely identifies an observation in its own table
**Foreign**: uniquely identifies an observation in another table

```{r}
planes %>% 
  count(tailnum) %>% # lets you quickly count the unique values of one or more variable
  filter(n > 1)

weather %>% 
  count(year, month, day, hour, origin) %>% 
  filter(n > 1)

flights %>%  #sometimes a table doesn't have an explicit primary key: each row has an observation but no combination is unique
  count(year, month, day, flight) %>% 
  filter(n > 1)

flights %>% 
  count(year, month, day, tailnum) %>% 
  filter(n > 1)
```

If a table lacks a primary key can be useful to add one with mutate() and row_number(). Makes it easier to match observations. This is called a surrogate key.
A primary and corresponding foreign key in another table for a relation. Relations are typically one-to-many. I.E. each flight has one plane, but one plane has many flights.

### 5.6.2 Mutating joins

Great tool for combining pairs of tables

```{r}
flights2 <- flights %>% 
  select(year:day, hour, origin, dest, tailnum, carrier)

flights2 %>%
  select(-origin, -dest) %>% 
  left_join(airlines, by = "carrier")

flights2 %>%
  select(-origin, -dest) %>% 
  mutate(name = airlines$name[match(carrier, airlines$carrier)])
```

```{r}
x <- tribble(
  ~key, ~val_x,
     1, "x1",
     2, "x2",
     3, "x3"
)
y <- tribble(
  ~key, ~val_y,
     1, "y1",
     2, "y2",
     4, "y3"
)
```


# Workshop 5 - Spatial data in R

### 6.4 Installing the spatial R packages

```{r}
# install and load your packages
#install.packages("sf")
#install.packages("terra")
#install.packages("tmap")

# Load into R library
#library(tidyverse)
library(sf) #simple features
library(terra) #for raster
library(tmap) # thematic maps are geographical maps in which spatial data distributions are visualized
```

### 6.6 Loading the spatial dataset

```{r}
#library(readr)
dat <- read_csv("~/JCU _2023/SP1/MB5370/Module4_R/github/mb5370/data/data-for-course/copepods_raw.csv")
dat
```
## 6.7 Data exploration

### 6.7.1 Check coordinates

```{r}
#library(ggplot2)
ggplot(dat) +
  aes(x = longitude, y = latitude, color = richness_raw) +
  geom_point() #looks good but NOT A MAP, doesn't include critical things to make a map including a projection (to bend or warp data over the earth) so that ral distances can be measured
```
#### Visualize richness data
```{r}
ggplot(dat, aes(x = latitude, y = richness_raw)) +
  stat_smooth() +
  geom_point()
```

## 6.8 Getting going with maps

*Let's turn our data into a "simple features collection"
```{r}
sdat <- st_as_sf(dat, coords = c("longitude", "latitude"), crs = 4326)
# st_as_sf converts different data types to simple features
#dat is our original data
#coords gives the names of the columns that relate to the spatial coordinates (in order of X coordinate followed by Y coordinate)
# crs stands for coordinate reference system which we will discuss next
```

## 6.9 Coordinate reference systems

```{r}
crs4326 <- st_crs(4326)
crs4326 # look at the CRS
crs4326$Name #pull out just the name of the crs
crs4326$wkt # crs in well-know text form
```

## 6.10 Feature collection (points)

```{r}
sdat #look at what we created with sdat
```

## 6.11 Catrography

```{r}
plot(sdat["richness_raw"]) #start with plotting simple features from sf
# use single brackets ["richness_raw"] to select a single variable

plot(sdat) #plots each variable, no single was specified
```

## 6.12 Thematic maps for communication

```{r}
#using tmap

tm1 <- tm_shape(sdat) +
  tm_dots(col = "richness_raw") #to plot dots of the coordinates. Other options are tm_symbols
tm1
```
**Note**: Can customize plots in a number of ways
```{r}
#save the map
tmap_save(tm1, filename = "Richness-map.png",
          width = 600, height = 600)
```


## 6.13 Mapping spatial polygons as layers

### 3.13.1 Loading shapefiles

```{r}
shelf <- st_read("~/JCU _2023/SP1/MB5370/Module4_R/github/mb5370/data/data-for-course/spatial-data/aus_shelf") #copied file path from files tab in R
aus <- st_read("~/JCU _2023/SP1/MB5370/Module4_R/github/mb5370/data/data-for-course/spatial-data/Aussie")
```

### 6.13.2 Mapping your polygons

```{r}
tm_shape(shelf) + #Creates a tmap-element that specifies a spatial data object, which we refer to as shape
  tm_polygons() #draw as polygon
```

#### Create a thematic map by layering

```{r}
tm_shape(shelf, bbox = sdat) + #shelf shpfile
  tm_polygons() + #plot the polygons
  tm_shape(aus) + #Aussie shpfile
  tm_polygons() + #plot the polygons
  tm_shape(sdat) + #copepod data
  tm_dots() + # plot the dot coordinates
  tmap_style("beaver") # change the color scheme of the map
  
```

```{r}
vignette("tmap-getstarted")
?tmap
```

```{r}
tm_shape(shelf, bbox = sdat) + #shelf shpfile
  tm_polygons() + #plot the polygons
  tm_shape(aus) + #Aussie shpfile
  tm_polygons() + #plot the polygons
  tm_shape(sdat) + #copepod data
  tm_dots() #+ # plot the dot coordinates
  #tmap_style("cobalt") # change the color scheme of the map
```

#### T-map Vignette Try the example codes

```{r}
library(tmap) #load the package
data("World") #built in data from sf package - good for exploring different functions in package

tm_shape(World) + #to plot need to specifiy first with tm_shape (like the first line of ggplot)
  tm_polygons("HPI") #+ #layer functions can be added after, in this case polygons
  #tmap_style("classic") #changes the default style of the map
```

Interactive Maps
```{r}
tmap_mode("view") #creates an interactive map where you can zoom in/out, click on attributes to get more information etc

tm_shape(World) +
  tm_polygons("HPI")
```

Mutliple shapes and layers
```{r}
data(World, metro, rivers, land) #call multiple datasets to use for a single map

tmap_mode("plot") #sets the map mode to plotting
tm_shape(land) +
  tm_raster("elevation", palette = terrain.colors(10)) + #draws a raster
tm_shape(World) +
  tm_borders("white", lwd = .5) + #draws borders of polygons
  tm_text("iso_a3", size = "AREA") + #adds labels
tm_shape(metro) +
  tm_symbols(col = "red", size = "pop2020", scale = 1) + #adds symbols to represent attributes in this case population
tm_legend(show = FALSE)
  
```

Facets
Can be created in 3 ways
1. By assigning multiple variable names to one aesthetic
```{r}
tmap_mode("view") #set map mode to view
tm_shape(World) +
  tm_polygons(c("HPI", "economy")) + # add polygons for both HPI & economy
  tm_facets(sync = TRUE, ncol = 2) # adds 2 facets, sync tells R to have both maps synced so you're looking at the same area in each facet
```

2. By splitting the spatial data with the by argument of tm_facets
```{r}
tmap_mode("plot") #set mode to plotting
data(NLD_muni) #call the data you want to use

NLD_muni$perc_men <- NLD_muni$pop_men / NLD_muni$population *100 #can map a function of the data for example the percent of men created from the above function

tm_shape(NLD_muni) +
  tm_polygons("perc_men", palette = "RdYlBu") + #add the polygon layers and set the palette
  tm_facets(by = "province") # facet the map by province

```

3. By using the **tmap_arrange** function
```{r}
tmap_mode("plot") #set mode to plotting

data(NLD_muni)
tm1 <- tm_shape(NLD_muni) + tm_polygons("population", convert2density = TRUE) #polygon map
tm2 <- tm_shape(NLD_muni) + tm_bubbles(size = "population") #circles correspond to population size

tmap_arrange(tm1, tm2) #arranges the two separate maps into one map with two facets
```

Basemaps and overlay tile maps
```{r}
tmap_mode("view") #set mode to interactive
tm_basemap("Stamen.Watercolor") + #  draws the tile layer as basemap (i.e. as bottom layer)
  tm_shape(metro) + tm_bubbles(size = "pop2020", col = "red") +
  tm_tiles("Stamen.TonerLabels") #draws the tile layer as overlay layer (where the stacking order corresponds to the order in which this layer is called)
```

Options and styles
```{r}
tmap_mode("plot") #set mode to plotting

tm_shape(World) +
  tm_polygons("HPI") +
tm_layout(bg.color = "skyblue", inner.margins = c(0, .02, .02, .02)) #this can be set globally using tmap_options so they don't have to be specified for each map



tmap_options(bg.color = "black", legend.text.color = "white")
tmap_mode("plot")
tm_shape(World) +
  tm_polygons("HPI", legend.title = "Happy Planet Index")

tmap_style("classic") #set map style to "classic"
tm_shape(World) +
  tm_polygons("HPI", legend.title = "Happy Planet Index")

tmap_options_diff() #see what options have been changed

tmap_options_reset() #resets options back to the default

#New styles can be created, see ?tmap_options

```

Exporting

tm <- tm_shape(World) +
    tm_polygons("HPI", legend.title = "Happy Planet Index")

## save an image ("plot" mode)
tmap_save(tm, filename = "world_map.png")

## save as stand-alone HTML file ("view" mode)
tmap_save(tm, filename = "world_map.html")


Quick thematic map - make a thematic map with one function call
```{r}
qtm(World, fill = "HPI", fill.pallete = "RdYlBu")
```
For tips and tricks run:
```{r}
tmap_tip()
```

## Making maps with R tutorial

```{r}
#for loading the data
library(raster)
library(readr)
library(readxl)
library(sf)

#for datasets
#install.packages("maps")
library(maps)
#install.packages("spData")
library(spData)


#for creating animations
#install.packages("magick")
library(magick)

#for plotting
#install.packages("grid")
library(grid)
library(tmap)
library(viridis)
```

Load Data
```{r}
#Load shapefile for bavaria
bavaria <- read_sf("~/JCU _2023/SP1/MB5370/Module4_R/github/mb5370/data/making_maps_with_r-master/datasets/chapter_2/bavaria.shp")

#Load raster file for europe
europe_raster <- raster("~/JCU _2023/SP1/MB5370/Module4_R/github/mb5370/data/making_maps_with_r-master/datasets/chapter_2/elevation1x1_new.tif")

#Load shapefile for world
world_shape <- read_sf("~/JCU _2023/SP1/MB5370/Module4_R/github/mb5370/data/making_maps_with_r-master/datasets/chapter_2/ne_50m_admin_0_countries.shp")

#keep only europe
europe_shape <- world_shape[world_shape$CONTINENT == "Europe",]

#use world.cities from the maps package
#keep only cities with at least 1 million inhabitants
cities <- world.cities[world.cities$pop >= 1000000, ]

#turn it into an sf object
cities <- cities %>%
  st_as_sf(coords = c("long", "lat"), crs = 4326) %>%
  st_cast("POINT")

#keep only cities that are in europe
cities <- st_intersection(cities, st_union(europe_shape))

#turn the europe object into a MULTILINESTRING
europe_shape <- st_cast(europe_shape, "MULTILINESTRING")
communities <- read_sf("~/JCU _2023/SP1/MB5370/Module4_R/github/mb5370/data/making_maps_with_r-master/datasets/chapter_2/gmd_ex.shp")

#keep only the ones in rosenheim
rosenheim <- communities[communities$BEZ_KRS == "Rosenheim", ]

#Load the csv file for honey production
honey_csv <- read_csv("~/JCU _2023/SP1/MB5370/Module4_R/github/mb5370/data/making_maps_with_r-master/datasets/chapter_2/honeyproduction.csv")

#Load the xlsx file for abbreviations of the us states
abbrev <- read_xlsx("~/JCU _2023/SP1/MB5370/Module4_R/github/mb5370/data/making_maps_with_r-master/datasets/chapter_2/abbrev.xlsx")

#Load honey shapefile
honey_sf <- read_sf("~/JCU _2023/SP1/MB5370/Module4_R/github/mb5370/data/making_maps_with_r-master/datasets/chapter_2/honey.shp")
```

Static maps with tmap

```{r}
bav1 <- tm_shape(bavaria) +
  tm_fill() #fills the individual polygons
bav2 <-tm_shape(bavaria) +
  tm_borders() #draws the borders of the individual polygons
bav3 <- tm_shape(bavaria) +
  tm_polygons() #ombines the two functions and displays both at the same time

#save the map as an object
map_europe <- tm_shape(europe_raster) + #saved object can be extended or retrieved at later time or additonal layers can be added
  tm_raster()
class(map_europe)

map_europe2 <- map_europe +
  tm_shape(europe_shape) +
  tm_lines(alpha = 0.3)
map_europe3 <- map_europe2 +
  tm_shape(cities) +
  tm_dots(size = 0.3)
map_europe2 #view the maps
map_europe3

tmap_arrange(bav1, bav2, bav3, ncol = 3) #multiple maps can be displayed next to or on top of one another
```

Change the aesthetics. Unlike ggplot with aes() arguments are passed directly. Some useful ones are fill color (col), transparency (alpha), line width (lwd), and line style (lty)

```{r}
bav4 <- tm_shape(bavaria) +
  tm_fill(col = "aquamarine")
bav5 <- tm_shape(bavaria) +
  tm_fill(col = "aquamarine", alpha = 0.5)
bav6 <- tm_shape(bavaria) +
  tm_polygons(col = "aquamarine", border.col = "darkolivegreen")
bav7 <- tm_shape(bavaria) +
  tm_borders(lwd = 2)
bav8 <- tm_shape(bavaria) +
  tm_polygons(col = "#E2E2E2", border.alpha = 0.5, lwd = 3)
tmap_arrange(bav1, bav4, bav5, bav6, bav7, bav8, ncol = 3)
```
Another difference to ggplot is that the variable names must be passed as characters and the $ operator can't be used

```{r}
tm_shape(bavaria) +
  tm_polygons(col = bavaria$pop_development)
```
Needs to be written as follows
```{r}
tm_shape(bavaria) +
  tm_polygons(col = "pop_development", midpoint = 0)
```

```{r}
#make column names easier to work with
colnames(bavaria) <- c(
  "place", "type", "gdp_per_capita", "mean_age",
  "pop_density", "unemployment_rate",
  "employment_rate", "household_income",
  "students", "pop_development", "geometry"
)
tm_shape(bavaria) +
  tm_polygons("pop_development", midpoint = 0) + #midpoint argument is used to set 0 as the natural midpoint
  tm_layout(legend.outside = TRUE)
#shows population is decreasing in northern bavaria

pal <- colorRampPalette(c("orange", "green"))
bavaria$order <- findInterval(bavaria$pop_development, sort(bavaria$pop_development))
plot(st_geometry(bavaria), col = pal(nrow(bavaria))[bavaria$order]) 
```
To use other intervals you can pass manual bins to the breaks argument or use n to specify the number of bins

```{r}
tm_shape(bavaria) +
  tm_polygons(col = "mean_age")
tm_shape(bavaria) +
  tm_polygons(col = "mean_age", breaks = c(40, 42, 46, 54))
tm_shape(bavaria) +
  tm_polygons(col = "mean_age", n = 3)
```

An alternate is the *style* argument. It allows the user to automatically create breaks by specifying algorithms. Here are some of the styles that can be used:
 - style = pretty: round interval boundaries to whole numbers (default settings)
 - style - equal: splits the variable into intervals of equal length. Should only be used if variable follows a uniform distribution
 - style = quantile: Splits the variable into quantiles. Consequently there are the same number of observations in each interval.
 - style = jenks: Identifies groups with similar values and maximizes the difference between them.
 - style = cont: Displays many colors over a continuous palette.
 - style = cat: Colors each category individually for categorical data.
Other possibilities are: cat, fixed, sd, kmeans, hclust, bclust, and fisher. 
```{r, , fig.align="center",fig.cap="Diffrent styles", echo = FALSE, fig.width= 8, fig.height= 8, warning=FALSE, message=FALSE}
ba41 <- tm_shape(bavaria) +
  tm_polygons(col = "unemployment_rate", style = "pretty", title = "unemp_rate") +
  tm_credits('style = "pretty"', size = 1) +
  tm_layout(inner.margins = 0.1)
ba51 <- tm_shape(bavaria) +
  tm_polygons(col = "unemployment_rate", style = "equal", title = "unemp_rate") +
  tm_credits('style = "equal"', size = 1) +
  tm_layout(inner.margins = 0.1)
ba61 <- tm_shape(bavaria) +
  tm_polygons(col = "unemployment_rate", style = "quantile", title = "unemp_rate") +
  tm_credits('style = "quantile"', size = 1) +
  tm_layout(inner.margins = 0.1)
ba71 <- tm_shape(bavaria) +
  tm_polygons(col = "unemployment_rate", style = "jenks", title = "unemp_rate") +
  tm_credits('style = "jenks"', size = 1) +
  tm_layout(inner.margins = 0.1)
ba81 <- tm_shape(bavaria) +
  tm_polygons(col = "unemployment_rate", style = "cont", title = "unemp_rate") +
  tm_credits('style = "cont"', size = 1) +
  tm_layout(inner.margins = 0.1)
ba91 <- tm_shape(bavaria) +
  tm_polygons(col = "type", style = "cat") +
  tm_credits('style = "cat"', size = 1) +
  tm_layout(inner.margins = 0.1)
tmap_arrange(ba41, ba51, ba61, ba71, ba81, ba91, ncol = 3)
```
You can further customize the map further by choosing the color of the individual classes using the palette argument from RColorBrewer or Viridis

```{r}
tm_shape(bavaria) +
  tm_polygons(col = "unemployment_rate", palette = "viridis")
tm_shape(bavaria) +
  tm_polygons( col = "unemployment_rate", palette = "-viridis")
```

Adding additional elements including compass, scale bar, logo etc

```{r}
tm_shape(bavaria) +
  tm_polygons(col = "type", pal = c("white", "skyblue")) + #polygon layer and color palette
  tm_logo("~/JCU _2023/SP1/MB5370/Module4_R/github/mb5370/data/making_maps_with_r-master/datasets/chapter_2/bavaria.png", height = 2) + #add a logo to the map
  tm_scale_bar(position = c("left", "bottom"), width = 0.15) + #add the scale bar
  tm_compass(position = c("left", "top"), size = 2) #Add a north arrow
```

```{r}
tm_shape(bavaria) +
  tm_polygons() +
  tm_layout(title = "Bavaria", bg.color = "#228B22")

tm_shape(bavaria) +
  tm_polygons() +
  tm_layout(scale = 3, frame = FALSE)

tm_shape(bavaria) +
  tm_polygons(col = "type") +
  tm_layout(frame.lwd = 3, legend.position = c("left", "bottom"))

tm_shape(bavaria) +
  tm_polygons(col = "type") +
  tm_layout(inner.margins = 0.2, legend.show = F)
```

Can also change the font and font size, as well as other visual filters

```{r}
tm_shape(bavaria) +
  tm_polygons(col = "type") +
  tm_style("classic") #change the style

tm_shape(bavaria) +
  tm_polygons(col = "type") +
  tm_style("col_blind") #change the style colorblind friendly
```

Can also customize by combining several small maps into one large

```{r}
bbox <- st_bbox(rosenheim, crs = 4326) %>%
  st_as_sfc()
map_rosenheim <- tm_shape(rosenheim) +
  tm_polygons()
map_bavaria <- tm_shape(bavaria) +
  tm_polygons() +
  tm_shape(bbox) +
  tm_polygons(alpha = 0, border.col = "red", lwd = 3)
map_rosenheim
print(map_bavaria, vp = grid::viewport(0.8, 0.185, width = 0.2, height = 0.45)) #includes an inset to better display the information

```

```{r}
us_states2163 <- st_transform(us_states, 2163) #projection of states changed to an equal area projection

#difference between largest and smallest y values calculated for each of the three maps
us_states_range <- st_bbox(us_states2163)[4] - st_bbox(us_states2163)[2]
hawaii_range <- st_bbox(hawaii)[4] - st_bbox(hawaii)[2] #to do this bounding boxes are used
alaska_range <- st_bbox(alaska)[4] - st_bbox(alaska)[2]
us_states_hawaii_ratio <- hawaii_range / us_states_range
us_states_alaska_ratio <- alaska_range / us_states_range

#Next create the three maps, legend.is.portrait =FALSE ensures the legend is arranged horizontally instead of vertically

us_states_map <- tm_shape(us_states2163) +
  tm_polygons(
    col = "total_pop_15", #color scale
    breaks = c(
      0, 5000000, 10000000, 15000000, 20000000, #set breaks in scale
      25000000, 30000000, 35000000, 40000000
      ),
    title = "Population 2015 in millions",
    pal = c("#E1F5C4", "#EDE574", "#F9D423", "#FC913A", "#FF4E50"), #color palette
    labels = c( #labels for the legend
      "0-5", "5-10", "10-15", "15-20", "20-25",
      "25-30", "30-35", "35-40"
      ),
    legend.is.portrait = FALSE) +
  tm_layout(
    frame = FALSE,
    legend.outside = TRUE,
    legend.outside.position = "bottom"
    )
hawaii_map <- tm_shape(hawaii) +
  tm_polygons(
    col = "total_pop_15",
    breaks = c(
      0, 5000000, 10000000, 15000000, 20000000,
      25000000, 30000000, 35000000, 40000000
      ),
    pal = c("#E1F5C4", "#EDE574", "#F9D423", "#FC913A", "#FF4E50")) +
  tm_layout(
    title = "Hawaii",
    frame = FALSE,
    bg.color = NA,
    legend.show = FALSE,
    title.position = c("LEFT", "BOTTOM")
    )
alaska_map <- tm_shape(alaska) +
  tm_polygons(
    col = "total_pop_15",
    breaks = c(
      0, 5000000, 10000000, 15000000, 20000000,
      25000000, 30000000, 35000000, 40000000),
    pal = c("#E1F5C4", "#EDE574", "#F9D423", "#FC913A", "#FF4E50")) +
  tm_layout(
    title = "Alaska",
    frame = FALSE,
    bg.color = NA,
    legend.show = FALSE,
    title.position = c("LEFT", "TOP")
    )

```

With grid.layout, a window with 2 rows and one column
```{r}
pushViewport(
  viewport(
    layout = grid.layout(
      2, 1, heights = unit(c(us_states_alaska_ratio, 1), "null")
      )
    )
  )
print(
  alaska_map,
  vp = viewport(layout.pos.row = 1)
  )
print(
  us_states_map,
  vp = viewport(layout.pos.row = 2)
  )
print(
  hawaii_map,
  vp = viewport(
    x = 0.1, y = 0.07,
    height = us_states_hawaii_ratio / sum(c(us_states_alaska_ratio, 1))
    )
  )
grid.lines(x = c(0, 1), y = c(0.58, 0.58), gp = gpar(lty = 2))
grid.lines(x = c(0, 0.2), y = c(0.33, 0), gp = gpar(lty = 2))
```

If a temporal variable is to be plotted, this is difficult to do with a map, because the geometries would often overlap. Especially in these cases the use of faceted maps is useful. The function has five important arguments:

 - by: According to which variable should be split?
 - nrow / ncol: The number of rows or columns of the facets
 - free.cords: Should each individual map have its own coordinate system?
 - along: Which variable should be used for animation?
 
```{r}
honey0912 <- honey_csv[honey_csv$year > 2008, ] #select the years starting in 2009
honey0912 <- rbind( # bind missing data to the original data
  honey0912,
  #create an empty matrix for all states that are missing
  matrix(
    NA,
    ncol = ncol(honey0912),
    nrow = 4 * length(
      unique(abbrev$state)[!unique(abbrev$state) %in% unique(honey0912$state)]
    ), dimnames = list(
      c(
        seq_len(
          4 * length(
            unique(abbrev$state)[!unique(abbrev$state) %in% unique(honey0912$state)])
          )
        ),
      colnames(honey0912)
      )
    )
  )
# add the missing state names
honey0912[
  is.na(honey0912$state), ]$state <- sort(
    rep(unique(abbrev$state)[!unique(abbrev$state) %in% unique(honey0912$state)], 4)
    )
# add the year for the missing states
honey0912[is.na(honey0912$year), ]$year <- rep(2009:2012, 10)
# merge the honey dataset with the state abbreviations
honey0912 <-  merge.data.frame(honey0912, abbrev, by = "state")
# change the colnames of our two datasets for merging
colnames(honey0912)[c(1, 9)] <- c("short", "State")
# use the us_states data from spData
colnames(us_states)[2] <- "State"
# remove the district of columbia from the us_states dataset from spData
us_states <- us_states[us_states$State != "District of Columbia", ]
# merge the data together
honey0912 <- merge(honey0912, us_states[, c(2, 7)], by = "State", all.y = TRUE)
# turn it into an sf object
honey0912 <- st_as_sf(honey0912)
tm_shape(honey0912) +
  tm_polygons(
    col = "priceperlb",
    style = "cont",
    pal = viridis(10, direction = -1),
    title = "Price in US$ per lb"
    ) +
  tm_facets(by = "year", ncol = 2) +
  tm_layout(legend.outside.size = 0.2)

```

#### Animated maps using magick

```{r}
#install.packages("installr")
library(installr)
#install.packages("gifski")
library(gifski)

installr::install.imagemagick()

honey_animation <- tm_shape(honey_sf) +
  tm_polygons(
    col = "prcprlb",
    style = "cont",
    pal = viridis(10, direction = -1)
    ) +
  tm_facets(along = "year") +
  tm_layout(legend.position = c("left", "bottom"))
tmap_animation(
  honey_animation, filename = "honey.gif",
  delay = 50, width = 2400, height = 1200
  )
```

### Interactive maps with R

```{r}
tmap_mode("view")

tm_shape(bavaria) +
  tm_polygons(col = "pop_development", midpoint = 0) +
  tm_basemap("Stamen.Watercolor")
```

```{r}
tm_shape(bavaria) +
  tm_polygons(col = "unemployment_rate") +
  tm_facets(by = "type") #create multiple facets within the view mode
```

```{r}
accidents <- read_csv("~/JCU _2023/SP1/MB5370/Module4_R/github/mb5370/data/making_maps_with_r-master/datasets/chapter_2/accidents.csv") #load dataset

accidents <- accidents %>%
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326) %>%
  st_cast("POINT") #transform to sf

london <- read_sf("~/JCU _2023/SP1/MB5370/Module4_R/github/mb5370/data/making_maps_with_r-master/datasets/chapter_2/London_Borough_Excluding_MHW.shp") %>%
  st_transform(4326)#load dataset

london_union <- st_union(london)
accidents_m <- st_intersects(london_union, accidents) #intersects calculated
accidents <- accidents[unlist(accidents_m)]

#select districts and calculate intersects
london <- london[london$NAME %in% c("City of London", "Westminster", "Camden"), ]
london <- st_union(london)
accidents_m <- st_intersects(london, accidents)
accidents <- accidents[unlist(accidents_m), ]


#Display the map

# do some ordering for the legend
accidents$Light_Conditions <- ordered(
  accidents$Light_Conditions,
  levels = c(
    "Daylight",
    "Darkness - lights lit",
    "Darkness - lighting unknown",
    "Darkness - lights unlit",
    "Darkness - no lighting",
    "Data missing or out of range"
    )
  )
# define the map
map_london <- tm_shape(accidents) +
  tm_dots(
    group = "2017",
    col = "Light_Conditions",
    palette = "Dark2",
    popup.vars = TRUE
    ) +
  tm_view(
    alpha = 1,
    basemaps = "Esri.WorldTopoMap"
    )
map_london
```

```{r}
#install.packages(c("dbscan", "dplyr", "extrafont", "geosphere", "ggplot2", "ggspatial", "grid",
 # "jsonlite", "lattice", "leaflet", "leaflet.extras", "leafpop", "magick", "mapdeck",
  #"magrittr", "maps", "mapview", "nycflights13", "openrouteservice", "patchwork",
  #"raster", "RColorBrewer", "readr", "readxl", "rgdal", "scico", "sf", "spData",
  #"tmap", "vapoRwave", "viridis"))
library(c("dbscan", "dplyr", "extrafont", "geosphere", "ggplot2", "ggspatial", "grid",
  "jsonlite", "lattice", "leaflet", "leaflet.extras", "leafpop", "magick", "mapdeck",
  "magrittr", "maps", "mapview", "nycflights13", "openrouteservice", "patchwork",
  "raster", "RColorBrewer", "readr", "readxl", "rgdal", "scico", "sf", "spData",
  "tmap", "vapoRwave", "viridis"))
```




























